{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTvw_jr-mjNR"
      },
      "source": [
        "**Resources used to get CNN working:**\n",
        "\n",
        "CNN notebook architecture reference video:\n",
        "https://www.youtube.com/watch?v=oPhxf2fXHkQ&list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4&index=13\n",
        "\n",
        "Wayne's previous CNN Project\n",
        "https://colab.research.google.com/drive/103d2kBaVF2L0jEnkgZKcJzgm1jZaqlbA?usp=sharing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "t356TUDJk9C-"
      },
      "outputs": [],
      "source": [
        "## imports ##\n",
        "\n",
        "import torch                                  ## pytorch package\n",
        "import torch.nn as nn                         ## pytorch neural network package\n",
        "import torch.optim as optim\n",
        "import torchvision                            ## see more at: https://pytorch.org/vision/stable/index.html\n",
        "import torchvision.transforms as transforms   ## image transformation package\n",
        "from torch.utils.data import Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "torch.set_printoptions(linewidth=120)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {},
      "outputs": [],
      "source": [
        "def imshow(image, ax=None, title=None, normalize=True):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    image = image.numpy().transpose((1, 2, 0))\n",
        "\n",
        "    if normalize:\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([0.229, 0.224, 0.225])\n",
        "        image = std * image + mean\n",
        "        image = np.clip(image, 0, 1)\n",
        "\n",
        "    ax.imshow(image)\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.spines['left'].set_visible(False)\n",
        "    ax.spines['bottom'].set_visible(False)\n",
        "    ax.tick_params(axis='both', length=0)\n",
        "    ax.set_xticklabels('')\n",
        "    ax.set_yticklabels('')\n",
        "\n",
        "    return ax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "s7Otf3PylhU3"
      },
      "outputs": [],
      "source": [
        "## device config\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "id": "UwWreeCxm8cc"
      },
      "outputs": [],
      "source": [
        "## hyper-parameters\n",
        "\n",
        "# input_size = None    # this will depend on each image size\n",
        "# hidden_size = None   # not sure what this is\n",
        "num_classes = 3   # number of classifications (i.e. number of different accents)\n",
        "num_epochs = 10    # number of iterations of the training set\n",
        "batch_size = 8    # the number of samples that will be propagated through the network each time\n",
        "learning_rate = 0.001 # steps towards the min loss "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "Nkn0xGuikmI_"
      },
      "outputs": [],
      "source": [
        "## data preparation ##\n",
        "'''\n",
        "    at this point, the data has been cleaned (i.e. reduced whitenoise and normalized) \n",
        "    and converted into melspectra stored in png\n",
        "    Each png has size = 432x288\n",
        "    Instead of spliting recordings into tens of classes, we decided to only go with three classes: English, Spanish and Arabic\n",
        "\n",
        "    # two key modules when loading data: \n",
        "    torch.utils.data.Dataset\tAn abstract class for representing a dataset\n",
        "    torch.utils.data.DataLoader\tWraps a dataset and provides access to the underlying data\n",
        "'''\n",
        "\n",
        "train_path = 'accent_melspectra/train'\n",
        "test_path = 'accent_melspectra/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([0.5420, 0.4600, 0.5431]), tensor([0.4353, 0.4592, 0.4039]))"
            ]
          },
          "execution_count": 164,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## calculating mean and std for transformation ##\n",
        "## TODO: learn how to calculate the mean\n",
        "## tutorial here: https://www.youtube.com/watch?v=z3kB3ISIPAg&t=343s\n",
        "## and here: https://towardsdatascience.com/how-to-calculate-the-mean-and-standard-deviation-normalizing-datasets-in-pytorch-704bd7d05f4c\n",
        "\n",
        "# resize the input images and convert them to tensor\n",
        "training_transform = transforms.Compose([transforms.Resize((256,256)), transforms.ToTensor()])\n",
        "train_dataset = torchvision.datasets.ImageFolder(root = train_path, transform=training_transform)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "def get_mean_and_std(loader):\n",
        "\n",
        "    mean = 0.\n",
        "    std = 0.\n",
        "    total_image_count = 0\n",
        "\n",
        "    for image, _ in loader:\n",
        "        image_count_in_batch = image.size(0)\n",
        "        # print(image.shape)\n",
        "        image = image.view(image_count_in_batch, image.size(1), -1)\n",
        "        # print(\"after\",image.shape)\n",
        "        mean += image.mean(2).sum(0)\n",
        "        std += image.std(2).sum(0)\n",
        "        total_image_count += image_count_in_batch\n",
        "    \n",
        "    mean /= total_image_count\n",
        "    std /= total_image_count\n",
        "\n",
        "    return mean, std\n",
        "\n",
        "get_mean_and_std(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {},
      "outputs": [],
      "source": [
        "mean = [0.5420, 0.4600, 0.5431]\n",
        "std = [0.4353, 0.4592, 0.4039]\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((256,256)),    # resize factors are arbitrarily chosen\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(torch.Tensor(mean), torch.Tensor(std))\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((256,256)),    # resize factors are arbitrarily chosen\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(torch.Tensor(mean), torch.Tensor(std))\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.ImageFolder(root=train_path, transform=train_transform)\n",
        "test_dataset = torchvision.datasets.ImageFolder(root=test_path, transform=test_transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "## currently the tensor that represents the batch should look like:\n",
        "# tensor([batch_size, 3, 256, 256])\n",
        "# tensor([batch_size, num_colors, height, width])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([1, 1, 2, 1, 1, 0, 2, 0, 1, 1, 1, 1, 1, 1, 2, 1])"
            ]
          },
          "execution_count": 166,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "## see if images are loaded correctly\n",
        "\n",
        "images, labels = next(iter(train_loader))\n",
        "imshow(images[0], normalize=False)\n",
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "Lpk1lFa5kxk_"
      },
      "outputs": [],
      "source": [
        "class NeuralNet(nn.Module): ## the class must extend from nn.module\n",
        "  def __init__(self):\n",
        "    super(NeuralNet,self).__init__()\n",
        "\n",
        "    ## layer parameters ##\n",
        "    \"\"\"\n",
        "      NOTE:\n",
        "        each layer is extended from pytorch's neural network module class\n",
        "        two items are encapsulated in each layer: a forward function definition and a weight tensor\n",
        "        weight_values in the weight_tensor are updated throughout the training process\n",
        "\n",
        "        In CNN, we typically work with 2 kinds of layers:\n",
        "          - convolutional layer\n",
        "          - linear (full-connected) layer\n",
        "          - when switching from convolutional layer to linear layer,\n",
        "            we need to flatten our input\n",
        "\n",
        "        hyper-parameters in these layers:\n",
        "          - kernel_size\n",
        "          - out_channels (number of filters)\n",
        "          - out_features (in linear layers)\n",
        "        \n",
        "        data-dependent parameters:\n",
        "          - in_channels in the first layer(number of color channels)\n",
        "          - out_features in the last channel = num_classes\n",
        "          - all in_channels and in_features should correspond to\n",
        "            the number of out_channel of the previous layer\n",
        "    \"\"\"\n",
        "    \n",
        "    #self.conv1 = nn.Conv2d(in_channels=number of colors incoming, out_channels=num of kernels, kernel_size=width of kernel)\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n",
        "    self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
        "    self.conv3 = nn.Conv2d(in_channels=12, out_channels=18, kernel_size=5)\n",
        "\n",
        "    ## before passing onto linear layers, output must be flattened\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features=18*12*12, out_features=120)\n",
        "    self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
        "    self.fc3 = nn.Linear(in_features=60, out_features=30)\n",
        "    self.out = nn.Linear(in_features=30, out_features=num_classes)\n",
        "\n",
        "  \n",
        "  def forward(self,t):\n",
        "    '''\n",
        "      the process of tranforming input data to a list of probabilities\n",
        "    '''\n",
        "    t = self.conv1(t)\n",
        "    t = nn.functional.relu(t)\n",
        "    t = nn.functional.max_pool2d(t, kernel_size=2, stride=2)\n",
        "\n",
        "    t = self.conv2(t)\n",
        "    t = nn.functional.relu(t)\n",
        "    t = nn.functional.max_pool2d(t, kernel_size=2, stride=2)\n",
        "\n",
        "    t = self.conv3(t)\n",
        "    t = nn.functional.relu(t)\n",
        "    t = nn.functional.max_pool2d(t, kernel_size=2, stride=5)\n",
        "\n",
        "    ## must reshape before passing into linear layer ##\n",
        "    t = t.reshape(-1, 18*12*12)\n",
        "\n",
        "    t = self.fc1(t)\n",
        "    t = nn.functional.relu(t)\n",
        "\n",
        "    t = self.fc2(t)\n",
        "    t = nn.functional.relu(t)\n",
        "\n",
        "    t = self.fc3(t)\n",
        "    t = nn.functional.relu(t)\n",
        "\n",
        "    # output tensor (should have 3 elements)\n",
        "    t = self.out(t)\n",
        "    #t = F.softmax(t,dim=1)  ## we will be using this in cross entropy function\n",
        "\n",
        "    return t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {},
      "outputs": [],
      "source": [
        "# torch.set_grad_enabled(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.1251,  0.0044,  0.0245]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "execution_count": 169,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## verifying the network works as expected before training\n",
        "network = NeuralNet()\n",
        "sample = next(iter(train_dataset))\n",
        "image, label = sample  ##\n",
        "# image.shape\n",
        "# print(label)\n",
        "# test_sample = image.unsqueeze(0)\n",
        "\n",
        "pred = network(test_sample) # we do this because we must pass batches of images into network instead of singles images\n",
        "pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.1270,  0.0052,  0.0229],\n",
            "        [-0.1261,  0.0059,  0.0245],\n",
            "        [-0.1265,  0.0063,  0.0245],\n",
            "        [-0.1267,  0.0057,  0.0238],\n",
            "        [-0.1273,  0.0060,  0.0238],\n",
            "        [-0.1259,  0.0058,  0.0242],\n",
            "        [-0.1272,  0.0050,  0.0238],\n",
            "        [-0.1265,  0.0053,  0.0244],\n",
            "        [-0.1272,  0.0058,  0.0240],\n",
            "        [-0.1266,  0.0049,  0.0227],\n",
            "        [-0.1279,  0.0053,  0.0230],\n",
            "        [-0.1269,  0.0049,  0.0230],\n",
            "        [-0.1262,  0.0055,  0.0247],\n",
            "        [-0.1266,  0.0057,  0.0240],\n",
            "        [-0.1265,  0.0059,  0.0253],\n",
            "        [-0.1264,  0.0064,  0.0236]], grad_fn=<AddmmBackward0>)\n",
            "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n"
          ]
        }
      ],
      "source": [
        "## still verifying...\n",
        "\n",
        "sample = next(iter(train_loader))\n",
        "images, labels = sample  ## images correspond to the batches now\n",
        "preds = network(images) # we do this because we must pass batches of images into network instead of singles images\n",
        "print(preds) # this genreates the prediction for one batch of images\n",
        "\n",
        "## we use the argmax function the find the index of image with largest likelihood\n",
        "\n",
        "max_index_pos_in_pred = preds.argmax(dim=1)\n",
        "print(max_index_pos_in_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_num_correct(preds, labels):\n",
        "    return preds.argmax(dim=1).eq(labels).sum().item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {
        "id": "hmgt5c_OFBCi"
      },
      "outputs": [],
      "source": [
        "## The actual training ##\n",
        "## useful resource: https://www.kaggle.com/kanncaa1/pytorch-tutorial-for-deep-learning-lovers\n",
        "network = NeuralNet() # create a network instance\n",
        "optimizer = optim.Adam(network.parameters(), lr=learning_rate)\n",
        "\n",
        "def start_training():\n",
        "\n",
        "    history = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        total_loss = 0\n",
        "        total_correct = 0\n",
        "\n",
        "        progress_counter = 0\n",
        "        for batch in train_loader:\n",
        "            images, labels = batch\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            preds = network(images)\n",
        "            loss = nn.functional.cross_entropy(preds, labels) ## calculate loss\n",
        "            loss.backward()\n",
        "            \n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_correct += get_num_correct(preds, labels)\n",
        "            progress_counter += 1\n",
        "            print(\"current batch progress: \", progress_counter / len(train_loader))\n",
        "        \n",
        "        print(\"Epoch: \", epoch, \"total correct: \", total_correct, \"total loss: \", total_loss)\n",
        "        history.append(total_loss)\n",
        "    \n",
        "    return total_correct, history\n",
        "\n",
        "# start_training()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current batch progress:  0.023809523809523808\n",
            "current batch progress:  0.047619047619047616\n",
            "current batch progress:  0.07142857142857142\n",
            "current batch progress:  0.09523809523809523\n",
            "current batch progress:  0.11904761904761904\n",
            "current batch progress:  0.14285714285714285\n",
            "current batch progress:  0.16666666666666666\n",
            "current batch progress:  0.19047619047619047\n",
            "current batch progress:  0.21428571428571427\n",
            "current batch progress:  0.23809523809523808\n",
            "current batch progress:  0.2619047619047619\n",
            "current batch progress:  0.2857142857142857\n",
            "current batch progress:  0.30952380952380953\n",
            "current batch progress:  0.3333333333333333\n",
            "current batch progress:  0.35714285714285715\n",
            "current batch progress:  0.38095238095238093\n",
            "current batch progress:  0.40476190476190477\n",
            "current batch progress:  0.42857142857142855\n",
            "current batch progress:  0.4523809523809524\n",
            "current batch progress:  0.47619047619047616\n",
            "current batch progress:  0.5\n",
            "current batch progress:  0.5238095238095238\n",
            "current batch progress:  0.5476190476190477\n",
            "current batch progress:  0.5714285714285714\n",
            "current batch progress:  0.5952380952380952\n",
            "current batch progress:  0.6190476190476191\n",
            "current batch progress:  0.6428571428571429\n",
            "current batch progress:  0.6666666666666666\n",
            "current batch progress:  0.6904761904761905\n",
            "current batch progress:  0.7142857142857143\n",
            "current batch progress:  0.7380952380952381\n",
            "current batch progress:  0.7619047619047619\n",
            "current batch progress:  0.7857142857142857\n",
            "current batch progress:  0.8095238095238095\n",
            "current batch progress:  0.8333333333333334\n",
            "current batch progress:  0.8571428571428571\n",
            "current batch progress:  0.8809523809523809\n",
            "current batch progress:  0.9047619047619048\n",
            "current batch progress:  0.9285714285714286\n",
            "current batch progress:  0.9523809523809523\n",
            "current batch progress:  0.9761904761904762\n",
            "current batch progress:  1.0\n",
            "Epoch:  0 total correct:  458 total loss:  38.22376301884651\n",
            "current batch progress:  0.023809523809523808\n",
            "current batch progress:  0.047619047619047616\n",
            "current batch progress:  0.07142857142857142\n",
            "current batch progress:  0.09523809523809523\n",
            "current batch progress:  0.11904761904761904\n",
            "current batch progress:  0.14285714285714285\n",
            "current batch progress:  0.16666666666666666\n",
            "current batch progress:  0.19047619047619047\n",
            "current batch progress:  0.21428571428571427\n",
            "current batch progress:  0.23809523809523808\n",
            "current batch progress:  0.2619047619047619\n",
            "current batch progress:  0.2857142857142857\n",
            "current batch progress:  0.30952380952380953\n",
            "current batch progress:  0.3333333333333333\n",
            "current batch progress:  0.35714285714285715\n",
            "current batch progress:  0.38095238095238093\n",
            "current batch progress:  0.40476190476190477\n",
            "current batch progress:  0.42857142857142855\n",
            "current batch progress:  0.4523809523809524\n",
            "current batch progress:  0.47619047619047616\n",
            "current batch progress:  0.5\n",
            "current batch progress:  0.5238095238095238\n",
            "current batch progress:  0.5476190476190477\n",
            "current batch progress:  0.5714285714285714\n",
            "current batch progress:  0.5952380952380952\n",
            "current batch progress:  0.6190476190476191\n",
            "current batch progress:  0.6428571428571429\n",
            "current batch progress:  0.6666666666666666\n",
            "current batch progress:  0.6904761904761905\n",
            "current batch progress:  0.7142857142857143\n",
            "current batch progress:  0.7380952380952381\n",
            "current batch progress:  0.7619047619047619\n",
            "current batch progress:  0.7857142857142857\n",
            "current batch progress:  0.8095238095238095\n",
            "current batch progress:  0.8333333333333334\n",
            "current batch progress:  0.8571428571428571\n",
            "current batch progress:  0.8809523809523809\n",
            "current batch progress:  0.9047619047619048\n",
            "current batch progress:  0.9285714285714286\n",
            "current batch progress:  0.9523809523809523\n",
            "current batch progress:  0.9761904761904762\n",
            "current batch progress:  1.0\n",
            "Epoch:  1 total correct:  458 total loss:  36.55133658647537\n",
            "current batch progress:  0.023809523809523808\n",
            "current batch progress:  0.047619047619047616\n",
            "current batch progress:  0.07142857142857142\n",
            "current batch progress:  0.09523809523809523\n",
            "current batch progress:  0.11904761904761904\n",
            "current batch progress:  0.14285714285714285\n",
            "current batch progress:  0.16666666666666666\n",
            "current batch progress:  0.19047619047619047\n",
            "current batch progress:  0.21428571428571427\n",
            "current batch progress:  0.23809523809523808\n",
            "current batch progress:  0.2619047619047619\n",
            "current batch progress:  0.2857142857142857\n",
            "current batch progress:  0.30952380952380953\n",
            "current batch progress:  0.3333333333333333\n",
            "current batch progress:  0.35714285714285715\n",
            "current batch progress:  0.38095238095238093\n",
            "current batch progress:  0.40476190476190477\n",
            "current batch progress:  0.42857142857142855\n",
            "current batch progress:  0.4523809523809524\n",
            "current batch progress:  0.47619047619047616\n",
            "current batch progress:  0.5\n",
            "current batch progress:  0.5238095238095238\n",
            "current batch progress:  0.5476190476190477\n",
            "current batch progress:  0.5714285714285714\n",
            "current batch progress:  0.5952380952380952\n",
            "current batch progress:  0.6190476190476191\n",
            "current batch progress:  0.6428571428571429\n",
            "current batch progress:  0.6666666666666666\n",
            "current batch progress:  0.6904761904761905\n",
            "current batch progress:  0.7142857142857143\n",
            "current batch progress:  0.7380952380952381\n",
            "current batch progress:  0.7619047619047619\n",
            "current batch progress:  0.7857142857142857\n",
            "current batch progress:  0.8095238095238095\n",
            "current batch progress:  0.8333333333333334\n",
            "current batch progress:  0.8571428571428571\n",
            "current batch progress:  0.8809523809523809\n",
            "current batch progress:  0.9047619047619048\n",
            "current batch progress:  0.9285714285714286\n",
            "current batch progress:  0.9523809523809523\n",
            "current batch progress:  0.9761904761904762\n",
            "current batch progress:  1.0\n",
            "Epoch:  2 total correct:  458 total loss:  35.67259156703949\n",
            "current batch progress:  0.023809523809523808\n",
            "current batch progress:  0.047619047619047616\n",
            "current batch progress:  0.07142857142857142\n",
            "current batch progress:  0.09523809523809523\n",
            "current batch progress:  0.11904761904761904\n",
            "current batch progress:  0.14285714285714285\n",
            "current batch progress:  0.16666666666666666\n",
            "current batch progress:  0.19047619047619047\n",
            "current batch progress:  0.21428571428571427\n",
            "current batch progress:  0.23809523809523808\n",
            "current batch progress:  0.2619047619047619\n",
            "current batch progress:  0.2857142857142857\n",
            "current batch progress:  0.30952380952380953\n",
            "current batch progress:  0.3333333333333333\n",
            "current batch progress:  0.35714285714285715\n",
            "current batch progress:  0.38095238095238093\n",
            "current batch progress:  0.40476190476190477\n",
            "current batch progress:  0.42857142857142855\n",
            "current batch progress:  0.4523809523809524\n",
            "current batch progress:  0.47619047619047616\n",
            "current batch progress:  0.5\n",
            "current batch progress:  0.5238095238095238\n",
            "current batch progress:  0.5476190476190477\n",
            "current batch progress:  0.5714285714285714\n",
            "current batch progress:  0.5952380952380952\n",
            "current batch progress:  0.6190476190476191\n",
            "current batch progress:  0.6428571428571429\n",
            "current batch progress:  0.6666666666666666\n",
            "current batch progress:  0.6904761904761905\n",
            "current batch progress:  0.7142857142857143\n",
            "current batch progress:  0.7380952380952381\n",
            "current batch progress:  0.7619047619047619\n",
            "current batch progress:  0.7857142857142857\n",
            "current batch progress:  0.8095238095238095\n",
            "current batch progress:  0.8333333333333334\n",
            "current batch progress:  0.8571428571428571\n",
            "current batch progress:  0.8809523809523809\n",
            "current batch progress:  0.9047619047619048\n",
            "current batch progress:  0.9285714285714286\n",
            "current batch progress:  0.9523809523809523\n",
            "current batch progress:  0.9761904761904762\n",
            "current batch progress:  1.0\n",
            "Epoch:  3 total correct:  458 total loss:  35.173295378685\n",
            "current batch progress:  0.023809523809523808\n",
            "current batch progress:  0.047619047619047616\n",
            "current batch progress:  0.07142857142857142\n",
            "current batch progress:  0.09523809523809523\n",
            "current batch progress:  0.11904761904761904\n",
            "current batch progress:  0.14285714285714285\n",
            "current batch progress:  0.16666666666666666\n",
            "current batch progress:  0.19047619047619047\n",
            "current batch progress:  0.21428571428571427\n",
            "current batch progress:  0.23809523809523808\n",
            "current batch progress:  0.2619047619047619\n",
            "current batch progress:  0.2857142857142857\n",
            "current batch progress:  0.30952380952380953\n",
            "current batch progress:  0.3333333333333333\n",
            "current batch progress:  0.35714285714285715\n",
            "current batch progress:  0.38095238095238093\n",
            "current batch progress:  0.40476190476190477\n",
            "current batch progress:  0.42857142857142855\n",
            "current batch progress:  0.4523809523809524\n",
            "current batch progress:  0.47619047619047616\n",
            "current batch progress:  0.5\n",
            "current batch progress:  0.5238095238095238\n",
            "current batch progress:  0.5476190476190477\n",
            "current batch progress:  0.5714285714285714\n",
            "current batch progress:  0.5952380952380952\n",
            "current batch progress:  0.6190476190476191\n",
            "current batch progress:  0.6428571428571429\n",
            "current batch progress:  0.6666666666666666\n",
            "current batch progress:  0.6904761904761905\n",
            "current batch progress:  0.7142857142857143\n",
            "current batch progress:  0.7380952380952381\n",
            "current batch progress:  0.7619047619047619\n",
            "current batch progress:  0.7857142857142857\n",
            "current batch progress:  0.8095238095238095\n",
            "current batch progress:  0.8333333333333334\n",
            "current batch progress:  0.8571428571428571\n",
            "current batch progress:  0.8809523809523809\n",
            "current batch progress:  0.9047619047619048\n",
            "current batch progress:  0.9285714285714286\n",
            "current batch progress:  0.9523809523809523\n",
            "current batch progress:  0.9761904761904762\n",
            "current batch progress:  1.0\n",
            "Epoch:  4 total correct:  458 total loss:  35.01514250040054\n",
            "current batch progress:  0.023809523809523808\n",
            "current batch progress:  0.047619047619047616\n",
            "current batch progress:  0.07142857142857142\n",
            "current batch progress:  0.09523809523809523\n",
            "current batch progress:  0.11904761904761904\n",
            "current batch progress:  0.14285714285714285\n",
            "current batch progress:  0.16666666666666666\n",
            "current batch progress:  0.19047619047619047\n",
            "current batch progress:  0.21428571428571427\n",
            "current batch progress:  0.23809523809523808\n",
            "current batch progress:  0.2619047619047619\n",
            "current batch progress:  0.2857142857142857\n",
            "current batch progress:  0.30952380952380953\n",
            "current batch progress:  0.3333333333333333\n",
            "current batch progress:  0.35714285714285715\n",
            "current batch progress:  0.38095238095238093\n",
            "current batch progress:  0.40476190476190477\n",
            "current batch progress:  0.42857142857142855\n",
            "current batch progress:  0.4523809523809524\n",
            "current batch progress:  0.47619047619047616\n",
            "current batch progress:  0.5\n",
            "current batch progress:  0.5238095238095238\n",
            "current batch progress:  0.5476190476190477\n",
            "current batch progress:  0.5714285714285714\n",
            "current batch progress:  0.5952380952380952\n",
            "current batch progress:  0.6190476190476191\n",
            "current batch progress:  0.6428571428571429\n",
            "current batch progress:  0.6666666666666666\n",
            "current batch progress:  0.6904761904761905\n",
            "current batch progress:  0.7142857142857143\n",
            "current batch progress:  0.7380952380952381\n",
            "current batch progress:  0.7619047619047619\n",
            "current batch progress:  0.7857142857142857\n",
            "current batch progress:  0.8095238095238095\n",
            "current batch progress:  0.8333333333333334\n",
            "current batch progress:  0.8571428571428571\n",
            "current batch progress:  0.8809523809523809\n",
            "current batch progress:  0.9047619047619048\n",
            "current batch progress:  0.9285714285714286\n",
            "current batch progress:  0.9523809523809523\n",
            "current batch progress:  0.9761904761904762\n",
            "current batch progress:  1.0\n",
            "Epoch:  5 total correct:  458 total loss:  35.06578770279884\n",
            "current batch progress:  0.023809523809523808\n",
            "current batch progress:  0.047619047619047616\n",
            "current batch progress:  0.07142857142857142\n",
            "current batch progress:  0.09523809523809523\n",
            "current batch progress:  0.11904761904761904\n",
            "current batch progress:  0.14285714285714285\n",
            "current batch progress:  0.16666666666666666\n",
            "current batch progress:  0.19047619047619047\n",
            "current batch progress:  0.21428571428571427\n",
            "current batch progress:  0.23809523809523808\n",
            "current batch progress:  0.2619047619047619\n",
            "current batch progress:  0.2857142857142857\n",
            "current batch progress:  0.30952380952380953\n",
            "current batch progress:  0.3333333333333333\n",
            "current batch progress:  0.35714285714285715\n",
            "current batch progress:  0.38095238095238093\n",
            "current batch progress:  0.40476190476190477\n",
            "current batch progress:  0.42857142857142855\n",
            "current batch progress:  0.4523809523809524\n",
            "current batch progress:  0.47619047619047616\n",
            "current batch progress:  0.5\n",
            "current batch progress:  0.5238095238095238\n",
            "current batch progress:  0.5476190476190477\n",
            "current batch progress:  0.5714285714285714\n",
            "current batch progress:  0.5952380952380952\n",
            "current batch progress:  0.6190476190476191\n",
            "current batch progress:  0.6428571428571429\n",
            "current batch progress:  0.6666666666666666\n",
            "current batch progress:  0.6904761904761905\n",
            "current batch progress:  0.7142857142857143\n",
            "current batch progress:  0.7380952380952381\n",
            "current batch progress:  0.7619047619047619\n",
            "current batch progress:  0.7857142857142857\n",
            "current batch progress:  0.8095238095238095\n",
            "current batch progress:  0.8333333333333334\n",
            "current batch progress:  0.8571428571428571\n",
            "current batch progress:  0.8809523809523809\n",
            "current batch progress:  0.9047619047619048\n",
            "current batch progress:  0.9285714285714286\n",
            "current batch progress:  0.9523809523809523\n",
            "current batch progress:  0.9761904761904762\n",
            "current batch progress:  1.0\n",
            "Epoch:  6 total correct:  458 total loss:  34.72323328256607\n",
            "current batch progress:  0.023809523809523808\n",
            "current batch progress:  0.047619047619047616\n",
            "current batch progress:  0.07142857142857142\n",
            "current batch progress:  0.09523809523809523\n",
            "current batch progress:  0.11904761904761904\n",
            "current batch progress:  0.14285714285714285\n",
            "current batch progress:  0.16666666666666666\n",
            "current batch progress:  0.19047619047619047\n",
            "current batch progress:  0.21428571428571427\n",
            "current batch progress:  0.23809523809523808\n",
            "current batch progress:  0.2619047619047619\n",
            "current batch progress:  0.2857142857142857\n",
            "current batch progress:  0.30952380952380953\n",
            "current batch progress:  0.3333333333333333\n",
            "current batch progress:  0.35714285714285715\n",
            "current batch progress:  0.38095238095238093\n",
            "current batch progress:  0.40476190476190477\n",
            "current batch progress:  0.42857142857142855\n",
            "current batch progress:  0.4523809523809524\n",
            "current batch progress:  0.47619047619047616\n",
            "current batch progress:  0.5\n",
            "current batch progress:  0.5238095238095238\n",
            "current batch progress:  0.5476190476190477\n",
            "current batch progress:  0.5714285714285714\n",
            "current batch progress:  0.5952380952380952\n",
            "current batch progress:  0.6190476190476191\n",
            "current batch progress:  0.6428571428571429\n",
            "current batch progress:  0.6666666666666666\n",
            "current batch progress:  0.6904761904761905\n",
            "current batch progress:  0.7142857142857143\n",
            "current batch progress:  0.7380952380952381\n",
            "current batch progress:  0.7619047619047619\n",
            "current batch progress:  0.7857142857142857\n",
            "current batch progress:  0.8095238095238095\n",
            "current batch progress:  0.8333333333333334\n",
            "current batch progress:  0.8571428571428571\n",
            "current batch progress:  0.8809523809523809\n",
            "current batch progress:  0.9047619047619048\n",
            "current batch progress:  0.9285714285714286\n",
            "current batch progress:  0.9523809523809523\n",
            "current batch progress:  0.9761904761904762\n",
            "current batch progress:  1.0\n",
            "Epoch:  7 total correct:  458 total loss:  33.519945442676544\n",
            "current batch progress:  0.023809523809523808\n",
            "current batch progress:  0.047619047619047616\n",
            "current batch progress:  0.07142857142857142\n",
            "current batch progress:  0.09523809523809523\n",
            "current batch progress:  0.11904761904761904\n",
            "current batch progress:  0.14285714285714285\n",
            "current batch progress:  0.16666666666666666\n",
            "current batch progress:  0.19047619047619047\n",
            "current batch progress:  0.21428571428571427\n",
            "current batch progress:  0.23809523809523808\n",
            "current batch progress:  0.2619047619047619\n",
            "current batch progress:  0.2857142857142857\n",
            "current batch progress:  0.30952380952380953\n",
            "current batch progress:  0.3333333333333333\n",
            "current batch progress:  0.35714285714285715\n",
            "current batch progress:  0.38095238095238093\n",
            "current batch progress:  0.40476190476190477\n",
            "current batch progress:  0.42857142857142855\n",
            "current batch progress:  0.4523809523809524\n",
            "current batch progress:  0.47619047619047616\n",
            "current batch progress:  0.5\n",
            "current batch progress:  0.5238095238095238\n",
            "current batch progress:  0.5476190476190477\n",
            "current batch progress:  0.5714285714285714\n",
            "current batch progress:  0.5952380952380952\n",
            "current batch progress:  0.6190476190476191\n",
            "current batch progress:  0.6428571428571429\n",
            "current batch progress:  0.6666666666666666\n",
            "current batch progress:  0.6904761904761905\n",
            "current batch progress:  0.7142857142857143\n",
            "current batch progress:  0.7380952380952381\n",
            "current batch progress:  0.7619047619047619\n",
            "current batch progress:  0.7857142857142857\n",
            "current batch progress:  0.8095238095238095\n",
            "current batch progress:  0.8333333333333334\n",
            "current batch progress:  0.8571428571428571\n",
            "current batch progress:  0.8809523809523809\n",
            "current batch progress:  0.9047619047619048\n",
            "current batch progress:  0.9285714285714286\n",
            "current batch progress:  0.9523809523809523\n",
            "current batch progress:  0.9761904761904762\n",
            "current batch progress:  1.0\n",
            "Epoch:  8 total correct:  458 total loss:  30.193184942007065\n",
            "current batch progress:  0.023809523809523808\n",
            "current batch progress:  0.047619047619047616\n",
            "current batch progress:  0.07142857142857142\n",
            "current batch progress:  0.09523809523809523\n",
            "current batch progress:  0.11904761904761904\n",
            "current batch progress:  0.14285714285714285\n",
            "current batch progress:  0.16666666666666666\n",
            "current batch progress:  0.19047619047619047\n",
            "current batch progress:  0.21428571428571427\n",
            "current batch progress:  0.23809523809523808\n",
            "current batch progress:  0.2619047619047619\n",
            "current batch progress:  0.2857142857142857\n",
            "current batch progress:  0.30952380952380953\n",
            "current batch progress:  0.3333333333333333\n",
            "current batch progress:  0.35714285714285715\n",
            "current batch progress:  0.38095238095238093\n",
            "current batch progress:  0.40476190476190477\n",
            "current batch progress:  0.42857142857142855\n",
            "current batch progress:  0.4523809523809524\n",
            "current batch progress:  0.47619047619047616\n",
            "current batch progress:  0.5\n",
            "current batch progress:  0.5238095238095238\n",
            "current batch progress:  0.5476190476190477\n",
            "current batch progress:  0.5714285714285714\n",
            "current batch progress:  0.5952380952380952\n",
            "current batch progress:  0.6190476190476191\n",
            "current batch progress:  0.6428571428571429\n",
            "current batch progress:  0.6666666666666666\n",
            "current batch progress:  0.6904761904761905\n",
            "current batch progress:  0.7142857142857143\n",
            "current batch progress:  0.7380952380952381\n",
            "current batch progress:  0.7619047619047619\n",
            "current batch progress:  0.7857142857142857\n",
            "current batch progress:  0.8095238095238095\n",
            "current batch progress:  0.8333333333333334\n",
            "current batch progress:  0.8571428571428571\n",
            "current batch progress:  0.8809523809523809\n",
            "current batch progress:  0.9047619047619048\n",
            "current batch progress:  0.9285714285714286\n",
            "current batch progress:  0.9523809523809523\n",
            "current batch progress:  0.9761904761904762\n",
            "current batch progress:  1.0\n",
            "Epoch:  9 total correct:  457 total loss:  30.375287264585495\n",
            "training correct percentage =  0.6861861861861862\n",
            "[38.22376301884651, 36.55133658647537, 35.67259156703949, 35.173295378685, 35.01514250040054, 35.06578770279884, 34.72323328256607, 33.519945442676544, 30.193184942007065, 30.375287264585495]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "### Evaluating the training set ###\n",
        "total_correct, history = start_training()\n",
        "correct_percent = total_correct / len(train_dataset)\n",
        "print(\"training correct percentage = \", correct_percent)\n",
        "plt.xlabel(\"Number of Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(history)\n",
        "print(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {
        "id": "jwbhXuu2vKR8"
      },
      "outputs": [],
      "source": [
        "## The actual testing ##\n",
        "\n",
        "def start_testing():\n",
        "    for epoch in range(num_epochs):\n",
        "        total_correct = 0\n",
        "        total_loss = 0\n",
        "        progress_counter = 0\n",
        "\n",
        "        for batch in test_loader:\n",
        "            with torch.no_grad():\n",
        "                network.eval()\n",
        "                images, labels = batch\n",
        "                preds = network(images)\n",
        "                loss = nn.functional.cross_entropy(preds, labels) ## calculate loss\n",
        "                \n",
        "                total_loss += loss.item()\n",
        "                total_correct += get_num_correct(preds, labels)\n",
        "                progress_counter += 1\n",
        "                print(\"current batch progress: \", progress_counter / len(train_loader))\n",
        "        \n",
        "        print(\"Epoch: \", epoch, \"total correct: \", total_correct, \"total loss: \", total_loss)\n",
        "    \n",
        "    return total_correct\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current batch progress:  0.023809523809523808\n",
            "current batch progress:  0.047619047619047616\n",
            "current batch progress:  0.07142857142857142\n",
            "current batch progress:  0.09523809523809523\n",
            "current batch progress:  0.11904761904761904\n",
            "current batch progress:  0.14285714285714285\n",
            "current batch progress:  0.16666666666666666\n",
            "current batch progress:  0.19047619047619047\n",
            "current batch progress:  0.21428571428571427\n",
            "current batch progress:  0.23809523809523808\n",
            "current batch progress:  0.2619047619047619\n",
            "Epoch:  0 total correct:  117 total loss:  11.579944014549255\n",
            "current batch progress:  0.023809523809523808\n",
            "current batch progress:  0.047619047619047616\n",
            "current batch progress:  0.07142857142857142\n",
            "current batch progress:  0.09523809523809523\n",
            "current batch progress:  0.11904761904761904\n",
            "current batch progress:  0.14285714285714285\n",
            "current batch progress:  0.16666666666666666\n",
            "current batch progress:  0.19047619047619047\n",
            "current batch progress:  0.21428571428571427\n",
            "current batch progress:  0.23809523809523808\n",
            "current batch progress:  0.2619047619047619\n",
            "Epoch:  1 total correct:  117 total loss:  11.579944014549255\n",
            "current batch progress:  0.023809523809523808\n",
            "current batch progress:  0.047619047619047616\n",
            "current batch progress:  0.07142857142857142\n",
            "current batch progress:  0.09523809523809523\n",
            "current batch progress:  0.11904761904761904\n",
            "current batch progress:  0.14285714285714285\n",
            "current batch progress:  0.16666666666666666\n",
            "current batch progress:  0.19047619047619047\n",
            "current batch progress:  0.21428571428571427\n",
            "current batch progress:  0.23809523809523808\n",
            "current batch progress:  0.2619047619047619\n",
            "Epoch:  2 total correct:  117 total loss:  11.579944014549255\n",
            "current batch progress:  0.023809523809523808\n",
            "current batch progress:  0.047619047619047616\n",
            "current batch progress:  0.07142857142857142\n",
            "current batch progress:  0.09523809523809523\n",
            "current batch progress:  0.11904761904761904\n",
            "current batch progress:  0.14285714285714285\n",
            "current batch progress:  0.16666666666666666\n",
            "current batch progress:  0.19047619047619047\n",
            "current batch progress:  0.21428571428571427\n",
            "current batch progress:  0.23809523809523808\n",
            "current batch progress:  0.2619047619047619\n",
            "Epoch:  3 total correct:  117 total loss:  11.579944014549255\n",
            "current batch progress:  0.023809523809523808\n",
            "current batch progress:  0.047619047619047616\n",
            "current batch progress:  0.07142857142857142\n",
            "current batch progress:  0.09523809523809523\n",
            "current batch progress:  0.11904761904761904\n",
            "current batch progress:  0.14285714285714285\n",
            "current batch progress:  0.16666666666666666\n",
            "current batch progress:  0.19047619047619047\n",
            "current batch progress:  0.21428571428571427\n",
            "current batch progress:  0.23809523809523808\n",
            "current batch progress:  0.2619047619047619\n",
            "Epoch:  4 total correct:  117 total loss:  11.579944014549255\n",
            "current batch progress:  0.023809523809523808\n",
            "current batch progress:  0.047619047619047616\n",
            "current batch progress:  0.07142857142857142\n",
            "current batch progress:  0.09523809523809523\n",
            "current batch progress:  0.11904761904761904\n",
            "current batch progress:  0.14285714285714285\n",
            "current batch progress:  0.16666666666666666\n",
            "current batch progress:  0.19047619047619047\n",
            "current batch progress:  0.21428571428571427\n",
            "current batch progress:  0.23809523809523808\n",
            "current batch progress:  0.2619047619047619\n",
            "Epoch:  5 total correct:  117 total loss:  11.579944014549255\n",
            "current batch progress:  0.023809523809523808\n",
            "current batch progress:  0.047619047619047616\n",
            "current batch progress:  0.07142857142857142\n",
            "current batch progress:  0.09523809523809523\n",
            "current batch progress:  0.11904761904761904\n",
            "current batch progress:  0.14285714285714285\n",
            "current batch progress:  0.16666666666666666\n",
            "current batch progress:  0.19047619047619047\n",
            "current batch progress:  0.21428571428571427\n",
            "current batch progress:  0.23809523809523808\n",
            "current batch progress:  0.2619047619047619\n",
            "Epoch:  6 total correct:  117 total loss:  11.579944014549255\n",
            "current batch progress:  0.023809523809523808\n",
            "current batch progress:  0.047619047619047616\n",
            "current batch progress:  0.07142857142857142\n",
            "current batch progress:  0.09523809523809523\n",
            "current batch progress:  0.11904761904761904\n",
            "current batch progress:  0.14285714285714285\n",
            "current batch progress:  0.16666666666666666\n",
            "current batch progress:  0.19047619047619047\n",
            "current batch progress:  0.21428571428571427\n",
            "current batch progress:  0.23809523809523808\n",
            "current batch progress:  0.2619047619047619\n",
            "Epoch:  7 total correct:  117 total loss:  11.579944014549255\n",
            "current batch progress:  0.023809523809523808\n",
            "current batch progress:  0.047619047619047616\n",
            "current batch progress:  0.07142857142857142\n",
            "current batch progress:  0.09523809523809523\n",
            "current batch progress:  0.11904761904761904\n",
            "current batch progress:  0.14285714285714285\n",
            "current batch progress:  0.16666666666666666\n",
            "current batch progress:  0.19047619047619047\n",
            "current batch progress:  0.21428571428571427\n",
            "current batch progress:  0.23809523809523808\n",
            "current batch progress:  0.2619047619047619\n",
            "Epoch:  8 total correct:  117 total loss:  11.579944014549255\n",
            "current batch progress:  0.023809523809523808\n",
            "current batch progress:  0.047619047619047616\n",
            "current batch progress:  0.07142857142857142\n",
            "current batch progress:  0.09523809523809523\n",
            "current batch progress:  0.11904761904761904\n",
            "current batch progress:  0.14285714285714285\n",
            "current batch progress:  0.16666666666666666\n",
            "current batch progress:  0.19047619047619047\n",
            "current batch progress:  0.21428571428571427\n",
            "current batch progress:  0.23809523809523808\n",
            "current batch progress:  0.2619047619047619\n",
            "Epoch:  9 total correct:  117 total loss:  11.579944014549255\n",
            "testing correct percentage =  0.6763005780346821\n"
          ]
        }
      ],
      "source": [
        "### Evaluating the training set\n",
        "total_correct = start_testing()\n",
        "correct_percent = total_correct / len(test_dataset)\n",
        "print(\"testing correct percentage = \", correct_percent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "final_project_CNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
